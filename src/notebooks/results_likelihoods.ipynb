{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the model likelihood of the same sentence under two models.\n",
    "\n",
    "> :warning: **Environment**: ipython has a lot of dependencies and is not in the main training environment. Hence this needs to run under a seperate one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple, List\n",
    "import itertools\n",
    "import sys\n",
    "import rich\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from notebooks.utils import styles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load data from pickle files and store in DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP THESE VARIABLES\n",
    "run_names = [\"6e43-10b0\", \"6385-5556\"]\n",
    "# removes the most likely samples that are not actually clearly OOD\n",
    "REMOVE_TOP_SAMPLES_G_LIKELIHOOD = 36 # start off with 0, and print the laoded data below. Find how many of the top samples in the D_F data are not clearly OOD (datasets are not perfectly clean). Then set that number here.\n",
    "# Set this name used for plotting and saving figures. e.g. \"MedicalQA\"\n",
    "EXPERIMENT_NAME = \"\"\n",
    "\n",
    "##### LOAD BY RUN NAMES\n",
    "\n",
    "paths = [\n",
    "    f\"/path/to/your/artifacts/model_likelihood/{run_name}/model_likelihood.pkl\" for run_name in run_names\n",
    "]\n",
    "\n",
    "print(paths)\n",
    "print(f\"Loaded {len(paths)} likelihod outputs.\")\n",
    "\n",
    "# in the data you load, datasets have names. specify which names are ID and which are OOD. Not all have to be in the dataset at the same time.\n",
    "DOMAIN = \"MedicalQA\"\n",
    "ID_NAMES = [\"pubmedqa\", \"pubmedqa_generated\"]\n",
    "\n",
    "\n",
    "# we remove all samples shorter than a threshold as they get very ambiguous whether they are ID or OOD.\n",
    "MIN_LENGTH = 10\n",
    "MAX_LENGTH = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_experiment_data(paths: List[str]) -> List[Dict]:\n",
    "    experiments = []\n",
    "\n",
    "    for path in paths:\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                experiments.append(pickle.load(f))\n",
    "        except:\n",
    "            print(f\"Could not load: {path}\")\n",
    "\n",
    "    # print laoded data\n",
    "    for i, experiment in enumerate(experiments):\n",
    "        print(experiment[\"config\"][\"data\"][\"name\"])\n",
    "        print(experiment[\"config\"][\"model\"][\"name_or_path\"])\n",
    "        print(experiment[\"config\"][\"generator\"][\"name_or_path\"])\n",
    "\n",
    "    # compute the log likelihoods\n",
    "    records = []\n",
    "    for i, experiment in enumerate(experiments):\n",
    "        data = experiment['data']\n",
    "        config = OmegaConf.to_container(experiment['config'])\n",
    "\n",
    "        # obtain the tokenizer and model from the config when tokenizers vary\n",
    "        if \"n_token_prompt\" not in data and config[\"tokenizers_match\"]:\n",
    "            data[\"n_token_prompt\"] = data[\"n_token_prompt_model\"]\n",
    "            data[\"sequence_length\"] = data[\"sequence_length_model\"]\n",
    "            data[\"x_text\"] = data[\"x_text_model\"]\n",
    "            data[\"y_text\"] = data[\"y_text_model\"]\n",
    "        else:\n",
    "            raise ValueError(\"No token prompt found.\")\n",
    "\n",
    "        N_samples = data[\"n_token_prompt\"].shape[0]\n",
    "        ll_model = data[\"log_likelihoods_model\"].sum(-1)\n",
    "        ll_generator = data[\"log_likelihoods_generator\"].sum(-1)\n",
    "        ll2_model = ll_model / np.log(2)\n",
    "        ll2_generator = ll_generator / np.log(2)\n",
    "        ll10_model = ll_model / np.log(10)\n",
    "        ll10_generator = ll_generator / np.log(10)\n",
    "        n_token_response =  data[\"sequence_length\"] - data[\"n_token_prompt\"].squeeze()\n",
    "\n",
    "        # loge_ratio = ll_model - ll_generator\n",
    "        log2_ratio = ll2_model - ll2_generator\n",
    "        norm_log2_ratio = log2_ratio / n_token_response\n",
    "\n",
    "        config_columns = pd.json_normalize(config)\n",
    "        dist_F = config_columns['model.target_distribution'][0]\n",
    "        dist_G = config_columns['generator.target_distribution'][0]\n",
    "\n",
    "        entropy_model = data[\"entropy_model\"].sum(-1)\n",
    "        entropy_generator = data[\"entropy_generator\"].sum(-1)\n",
    "\n",
    "        config_columns[\"distributions\"] = f\"F({dist_F})||G({dist_G})\"\n",
    "\n",
    "        if config[\"inference\"][\"prompt_length\"] == \"dataset\":\n",
    "            prompt_length = data[\"n_token_prompt\"].squeeze()\n",
    "        else:\n",
    "            prompt_length = np.full((N_samples,), int(config[\"inference\"][\"prompt_length\"]))\n",
    "\n",
    "        n_char_response = [len(x) for x in data[\"y_text\"]]\n",
    "\n",
    "        data_columns = pd.DataFrame({\n",
    "            \"ll2_model\": ll2_model,\n",
    "            \"ll2_generator\": ll2_generator,\n",
    "            \"ll10_model\": ll10_model,\n",
    "            \"ll10_generator\": ll10_generator,\n",
    "            \"ll2_model_norm\": ll2_model / n_token_response,\n",
    "            \"ll2_generator_norm\": ll2_generator / n_token_response,\n",
    "            \"ll10_model_norm\": ll10_model / n_token_response,\n",
    "            \"ll10_generator_norm\": ll10_generator / n_token_response,\n",
    "            \"log2_ratio\": log2_ratio,\n",
    "            \"log2_ratio_norm\": log2_ratio / n_token_response,\n",
    "            \"entropy_model\": entropy_model,\n",
    "            \"entropy_generator\": entropy_generator,\n",
    "            \"x\": data[\"x_text\"],\n",
    "            \"y\": data[\"y_text\"],\n",
    "            \"sequence_length\": data[\"sequence_length\"],\n",
    "            \"n_token_prompt\": data[\"n_token_prompt\"].squeeze(),\n",
    "            \"prompt_length\": prompt_length,\n",
    "            \"n_token_response\": n_token_response,\n",
    "            \"n_char_response\": n_char_response,\n",
    "        })\n",
    "\n",
    "        assert data_columns[\"n_token_response\"].min() > 0\n",
    "\n",
    "        # combine and repeat config_columns to match data_columns\n",
    "        config_columns = pd.concat([config_columns] * len(data_columns), ignore_index=True)\n",
    "        combined = pd.concat([config_columns, data_columns], axis=1)\n",
    "\n",
    "        records.append(combined)\n",
    "\n",
    "    df = pd.concat(records).copy()\n",
    "\n",
    "    # OOD is when data_config_name is not task_data_int_sort\n",
    "    df[\"OOD\"] = (~df[\"data_config_name\"].isin(ID_NAMES)).astype(int)\n",
    "    df[\"Dataset\"] = df[\"OOD\"].map({0: r\"Target Domain $\\mathcal{D}_{T}$\", 1: r\"Other $\\mathcal{D}_{F}$\"})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_experiment_data(paths)\n",
    "\n",
    "# print unique combinations of distributions and data_config_name\n",
    "df_unique_combinations = df[[\"distributions\", \"data_config_name\"]].drop_duplicates()\n",
    "print(df_unique_combinations)\n",
    "print(df.shape)\n",
    "\n",
    "print(f\"Model M: {df['model.name_or_path'].unique()}\")\n",
    "print(f\"Model G: {df['generator.name_or_path'].unique()}\")\n",
    "\n",
    "print(df.groupby([\"data_config_name\", \"distributions\"]).size().reset_index(name='counts'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataset\n",
    "\n",
    "1. Remove short responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_shape = df.shape\n",
    "if MIN_LENGTH is not None:\n",
    "    df = df.loc[df[\"n_token_response\"] >= MIN_LENGTH]\n",
    "    print(f\"Removed {df_original_shape[0] - df.shape[0]} rows with n_token_response < {MIN_LENGTH}. Remaining: {df.shape[0]}\")\n",
    "if MAX_LENGTH is not None:\n",
    "    df = df.loc[df[\"n_token_response\"] <= MAX_LENGTH]\n",
    "    print(f\"Removed {df_original_shape[0] - df.shape[0]} rows with n_token_response > {MAX_LENGTH}. Remaining: {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove responses that are not clearly OOD, but could in fact be ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the N samples with the highest `ll2_generator` values as first cleaning stragey.\n",
    "original_shape = df.shape\n",
    "df = df.sort_values(\"ll2_generator\", ascending=False)\n",
    "df = df.iloc[REMOVE_TOP_SAMPLES_G_LIKELIHOOD:] # SET THIS ABOVE.\n",
    "print(f\"Removed {original_shape[0] - df.shape[0]} samples with highest `ll2_generator` values. Remaining: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df.to_csv(f\"df_{DOMAIN}{EXPERIMENT_NAME}.csv\", index=False, sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_upper_bound_m(log_g: float, N: int, T: int, k: float) -> float:\n",
    "    return log_g + np.log2(T) + k * N\n",
    "\n",
    "def get_k_given_frr(df, frr: float):\n",
    "    k = df.loc[df[\"OOD\"] == 0, \"log2_ratio_norm\"].quantile(1 - frr)\n",
    "    return k\n",
    "\n",
    "def get_k_given_epsilon(e_log10: float, T: int, df: pd.DataFrame, k_min: float = 0, k_max: float = 10, max_iter: int = 100, tolerance: float = 1e-6, upper_quantile: float = 1.0) -> Tuple[float, float, float]:\n",
    "    e_log2 = e_log10 / np.log10(2)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        k_mid = (k_min + k_max) / 2\n",
    "        # Calculate log_upper_bounds for each row in the DataFrame\n",
    "        log_upper_bounds = df.apply(lambda row: get_log_upper_bound_m(row[\"ll2_generator\"], row[\"n_token_response\"], T, k_mid), axis=1)\n",
    "        max_log_upper_bound = log_upper_bounds.quantile(upper_quantile)\n",
    "        # print(f\"Current k: {k_mid}. k_min: {k_min}, k_max: {k_max} | Max log upper bound: {max_log_upper_bound} | e_log2: {e_log2}\")\n",
    "\n",
    "        # Check if the current max_log_upper_bound is within the tolerance\n",
    "        if abs(max_log_upper_bound - e_log2) < tolerance:\n",
    "            return (k_min, k_mid, k_max)\n",
    "\n",
    "        # Adjust the search range based on comparison\n",
    "        if max_log_upper_bound > e_log2:\n",
    "            k_max = k_mid\n",
    "        else:\n",
    "            k_min = k_mid\n",
    "\n",
    "    # check solution\n",
    "    if abs(max_log_upper_bound - e_log2) > tolerance:\n",
    "        print(f\"Solution not found within {max_iter} iterations. Current max_log_upper_bound: {max_log_upper_bound} | e_log2: {e_log2}\")\n",
    "\n",
    "    return (k_min, k_mid, k_max)\n",
    "\n",
    "def get_constriction_ratios_given_k(df: pd.DataFrame, k: float, T: int, return_base: str = \"log10\") -> np.ndarray:\n",
    "    # Calculate log_upper_bounds for each row in the DataFrame\n",
    "    log2_upper_bounds = df.apply(lambda row: get_log_upper_bound_m(row[\"ll2_generator\"], row[\"n_token_response\"], T, k), axis=1)\n",
    "    log2_cr = df[\"ll2_model\"] - log2_upper_bounds\n",
    "    if return_base == \"log2\":\n",
    "        return log2_cr.to_numpy()\n",
    "    if return_base == \"log10\":\n",
    "        # log 10 x = log 2 x / log 2 10\n",
    "        log10_cr = log2_cr / np.log2(10)\n",
    "        return log10_cr.to_numpy()\n",
    "    if return_base in [\"log\", \"loge\", \"ln\"]:\n",
    "        # log e x = log 2 x / log 2 e\n",
    "        log_cr = log2_cr / np.log2(np.e)\n",
    "        return log_cr.to_numpy()\n",
    "    if return_base in [\"p\", \"prob\", \"probability\"]:\n",
    "        # p(x) = 2 ^ log2(x)\n",
    "        p_cr = 2 ** log2_cr\n",
    "        return p_cr.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Table of bounds and thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell saves a table that is then loaded for the `resuts_benchmark.ipynb` notebook.\n",
    "\n",
    "T_list = [1]\n",
    "\n",
    "log10_eps_list = np.linspace(-50, 50, 501)\n",
    "upper_quantile = 1.0 # quantile for the DC bound. 1.0 is the maximum, < 1.0 might be appropriate, when datasets are clearly not clean and contain ID sequences. We use 1.0 here.\n",
    "\n",
    "def get_eps_table_from_epsilon(T_list: List[int], log10_eps_list: List[float], df: pd.DataFrame, upper_quantile: float = 1.0) -> pd.DataFrame:\n",
    "    pars = list(itertools.product(T_list, log10_eps_list))\n",
    "    results = []\n",
    "\n",
    "    for T, e_log10 in tqdm(pars):\n",
    "        k_min, k_mid, k_max = get_k_given_epsilon(e_log10, T, df, k_min=-100, k_max=100, max_iter=100, tolerance=1e-6, upper_quantile=upper_quantile)\n",
    "        constriction_ratios = get_constriction_ratios_given_k(df, k_mid, T, return_base=\"log10\")\n",
    "        results.append({\n",
    "            \"T\": T,\n",
    "            \"log10_eps\": e_log10,\n",
    "            \"k_min\": k_min,\n",
    "            \"k_mid\": k_mid,\n",
    "            \"k_max\": k_max,\n",
    "            \"log10_cr_10\": np.quantile(constriction_ratios, 0.1),\n",
    "            \"log10_cr_median\": np.median(constriction_ratios),\n",
    "            \"log10_cr_90\": np.quantile(constriction_ratios, 0.9),\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_id = df.loc[df[\"OOD\"] == 0]\n",
    "df_ood = df.loc[df[\"OOD\"] == 1]\n",
    "bound_table = get_eps_table_from_epsilon(T_list, log10_eps_list, df_ood, upper_quantile)\n",
    "save_path = os.path.abspath(f\"k_given_eps_table_{DOMAIN}{EXPERIMENT_NAME}_DC_quantile_{upper_quantile:.2f}.csv\")\n",
    "bound_table.to_csv(save_path, index=False, sep=\"\\t\", encoding=\"utf-8\")\n",
    "print(f\"Saved k_given_eps_table to {save_path}\")\n",
    "\n",
    "# print max ll2_generator and ll2_model for df_id and df_ood\n",
    "print(f\"Max ll2_generator for ID:  {df_id['ll2_generator'].max()}\")\n",
    "print(f\"Max ll2_model     for ID:  {df_id['ll2_model'].max()}\")\n",
    "print(f\"Max ll2_generator for OOD: {df_ood['ll2_generator'].max()}\")\n",
    "print(f\"Max ll2_model     for OOD: {df_ood['ll2_model'].max()}\")\n",
    "\n",
    "# now print the normalized versions:\n",
    "print(f\"Max ll2_generator_norm for ID:  {df_id['ll2_generator_norm'].max()}\")\n",
    "print(f\"Max ll2_model_norm     for ID:  {df_id['ll2_model_norm'].max()}\")\n",
    "print(f\"Max ll2_generator_norm for OOD: {df_ood['ll2_generator_norm'].max()}\")\n",
    "print(f\"Max ll2_model_norm     for OOD: {df_ood['ll2_model_norm'].max()}\")\n",
    "\n",
    "bound_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Log Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.clf()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(styles.third)\n",
    "\n",
    "hue_order = df[\"Dataset\"].unique()\n",
    "# hue_order = reversed(hue_order)\n",
    "palette = sns.palettes.color_palette(\"colorblind\", 2)\n",
    "palette = reversed(palette)\n",
    "g = sns.histplot(data=df.sort_values(\"Dataset\"), x=\"log2_ratio_norm\", hue=\"Dataset\", stat=\"density\", common_norm=False, bins=50, palette=palette, hue_order=hue_order)\n",
    "# turn off y axis label and ticks\n",
    "g.set(ylabel=None)\n",
    "g.set(yticklabels=[])\n",
    "# x axis label \"Log Likelihood Ratio\"\n",
    "g.set(xlabel=\"Normalized Log Likelihood Ratio\")\n",
    "# overwrite legend title to empty string\n",
    "g.get_legend().set_title(\"\")\n",
    "\n",
    "save_path = os.path.abspath(f\"likelihood_ratio_hist_{DOMAIN}{EXPERIMENT_NAME}.pdf\")\n",
    "plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constriction vs OOD Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table of detection and certiication metrics\n",
    "\n",
    "# set the range of k values\n",
    "k_min = df['log2_ratio_norm'].min() #  -250\n",
    "k_max = 10 # df['log2_ratio'].max() # 1600\n",
    "\n",
    "k_list  = np.linspace(k_min, k_max, 100)\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# compute the metrics for each k\n",
    "for k in k_list:\n",
    "    # get FPR, TPR, Youden's J for threshold k on the log2 ratio\n",
    "    preds = df['log2_ratio_norm'] > k\n",
    "    tn, fp, fn, tp = confusion_matrix(df['OOD'], preds).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    #### Calculate the log constriction ratio\n",
    "    # Apply the get_log_upper_bound_m function with current k\n",
    "    df[\"log2_upper_bound_m\"] = df.apply(lambda row: get_log_upper_bound_m(row[\"ll2_generator\"], row[\"n_token_response\"], 1, k), axis=1)\n",
    "\n",
    "    df[\"log10_upper_bound_m\"] = df[\"log2_upper_bound_m\"] / np.log2(10)\n",
    "    df[\"log10_upper_bound_f\"] = df[\"ll2_model\"] / np.log2(10)\n",
    "\n",
    "    # Calculate the log10 constriction ratio\n",
    "    df[\"log10_constriction_ratio\"] = df[\"log10_upper_bound_f\"] - df[\"log10_upper_bound_m\"]\n",
    "\n",
    "    df_ood = df.loc[df[\"OOD\"] == 1]\n",
    "    df_id = df.loc[df[\"OOD\"] == 0]\n",
    "\n",
    "    constriction = df_ood[\"log10_constriction_ratio\"].quantile(0.5)\n",
    "\n",
    "\n",
    "    metrics.append({\n",
    "        \"k\": k,\n",
    "        \"FRR\": fpr,\n",
    "        \"TRR\": tpr,\n",
    "        \"J\": tpr - fpr,\n",
    "        \"log10_constriction_ratio\": constriction\n",
    "    })\n",
    "metrics = pd.DataFrame(metrics)\n",
    "# print row of metrics with highest J\n",
    "print(metrics.loc[metrics[\"J\"].idxmax()])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x = Median Log10 Constriction Ratio, y = Youden's J, TPR and FPR\n",
    "plt.clf()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(styles.third)\n",
    "x_axis = \"log10_constriction_ratio\"\n",
    "g = sns.lineplot(data=metrics, x=x_axis, y=\"J\", label=\"Youden's J\")\n",
    "g = sns.lineplot(data=metrics, x=x_axis, y=\"TRR\", label=\"TRR\")\n",
    "g = sns.lineplot(data=metrics, x=x_axis, y=\"FRR\", label=\"FRR\")\n",
    "g.set(xlabel=r\"$\\text{log}_{10}$ Constriction Ratio (Median)\")\n",
    "g.set(ylabel=\"\")\n",
    "\n",
    "# Set y-ticks at 0 and 1\n",
    "g.set_yticks([0, 0.5, 1])\n",
    "\n",
    "# Move the legend box to the bottom left\n",
    "g.legend(loc='lower left')\n",
    "\n",
    "# gray dotted line at x=0\n",
    "plt.axvline(x=0, color=\"gray\", linestyle=\"--\")\n",
    "save_path = os.path.abspath(f\"constriction_ratio_metrics_{DOMAIN}{EXPERIMENT_NAME}.pdf\")\n",
    "plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRR vs Epsilon-Certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_log_min = -20 # -350\n",
    "e_log_max = 0\n",
    "T = 1\n",
    "\n",
    "e_log_list = np.linspace(e_log_min, e_log_max, 100)\n",
    "\n",
    "metrics = []\n",
    "\n",
    "df_ood = df.loc[df[\"OOD\"] == 1]\n",
    "g_ood_max = df_ood[\"ll2_generator\"].max()\n",
    "f_ood_max = df_ood[\"ll2_model\"].max()\n",
    "f_ood_max_log10 = f_ood_max / np.log2(10)\n",
    "\n",
    "for e_log in e_log_list:\n",
    "    k_solution = get_k_given_epsilon(e_log, T, df_ood, -10, 100)\n",
    "    k = k_solution[1]\n",
    "    # get FPR and TPR for threshold k on the log2 ratio\n",
    "    preds = df['log2_ratio_norm'] > k\n",
    "    tn, fp, fn, tp = confusion_matrix(df['OOD'], preds).ravel()\n",
    "\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "    metrics.append({\n",
    "        \"e_log\": e_log,\n",
    "        \"FRR\": fpr,\n",
    "        \"TRR\": tpr,\n",
    "        \"FAR\": fnr,\n",
    "        \"J\": tpr - fpr\n",
    "    })\n",
    "\n",
    "metrics = pd.DataFrame(metrics)\n",
    "\n",
    "metrics_long = pd.melt(metrics, id_vars=[\"e_log\"], value_vars=[\"FRR\", \"TRR\", \"FAR\", \"J\"], var_name=\"Metric\", value_name=\"Value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(styles.third)\n",
    "\n",
    "x_axis = \"e_log\"\n",
    "g = sns.lineplot(data=metrics, x=x_axis, y=\"FRR\", label=\"FRR\")\n",
    "\n",
    "g.set(ylabel=\"\")\n",
    "g.legend(loc='lower left')\n",
    "g.set(xlabel=r\"$\\text{Log}_{10}$ $\\epsilon$-DC\")\n",
    "\n",
    "plt.axvline(x=f_ood_max_log10, color=\"gray\", linestyle=\"--\")\n",
    "plt.text(f_ood_max_log10-3, 0.6, r\"$\\max_{\\mathcal{D}_{\\mathbb{F}}} L(\\mathbf{y}|\\mathbf{x})$\", rotation=90, verticalalignment=\"center\")\n",
    "\n",
    "save_path = os.path.abspath(f\"epsilon_dc_metrics_{DOMAIN}{EXPERIMENT_NAME}.pdf\")\n",
    "plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constriction Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_constriction_table(df, only_ood: bool = True):\n",
    "    df = df.copy()\n",
    "    target_distributions = \"F(y|x)||G(y)\"\n",
    "    df = df.loc[df[\"distributions\"] == target_distributions]\n",
    "    df_list = []\n",
    "    for frr in [0.0, 0.01, 0.05, 0.1, 0.2, 0.25, 0.5]:\n",
    "        k = get_k_given_frr(df, frr)\n",
    "        df[\"log2_upper_bound_m\"] = df.apply(lambda x: get_log_upper_bound_m(x[\"ll2_generator\"], x[\"n_token_response\"], 1, k), axis=1)\n",
    "        df[\"log10_upper_bound_m\"] = df[\"log2_upper_bound_m\"] / np.log2(10)\n",
    "        df[\"log10_upper_bound_f\"] = df[\"ll2_model\"] / np.log2(10)\n",
    "        df[\"log10_constriction_ratio\"] = df[\"log10_upper_bound_f\"] - df[\"log10_upper_bound_m\"]\n",
    "        df_ood = df.loc[df[\"OOD\"] == 1]\n",
    "\n",
    "        if only_ood:\n",
    "            median = df_ood.groupby(\"distributions\")[\"log10_constriction_ratio\"].median()\n",
    "            percentile_10 = df_ood.groupby(\"distributions\")[\"log10_constriction_ratio\"].quantile(0.1)\n",
    "            percentile_90 = df_ood.groupby(\"distributions\")[\"log10_constriction_ratio\"].quantile(0.9)\n",
    "        else:\n",
    "            median = df.groupby(\"distributions\")[\"log10_constriction_ratio\"].median()\n",
    "            percentile_10 = df.groupby(\"distributions\")[\"log10_constriction_ratio\"].quantile(0.1)\n",
    "            percentile_90 = df.groupby(\"distributions\")[\"log10_constriction_ratio\"].quantile(0.9)\n",
    "\n",
    "        # merge to table\n",
    "        df_upper_bound = pd.concat([percentile_10, median, percentile_90], axis=1)\n",
    "        df_upper_bound.columns = [\"10%\", \"median\", \"90%\"]\n",
    "\n",
    "        df_upper_bound[\"combined\"] = df_upper_bound.apply(lambda x: f\"{x['10%']:.0f} / {x['median']:.0f} / {x['90%']:.0f}\", axis=1)\n",
    "        df_upper_bound[\"FRR\"] = frr\n",
    "        df_upper_bound[\"k\"] = k\n",
    "        df_list.append(df_upper_bound)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "    save_path = os.path.abspath(f\"constriction_table_{DOMAIN}{EXPERIMENT_NAME}.csv\")\n",
    "    df[['FRR', 'k', 'combined']].to_csv(save_path)\n",
    "    print(f\"Saved constriction table to {save_path}\")\n",
    "\n",
    "    print(df)\n",
    "\n",
    "print_constriction_table(df, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constriction_ratios(df, frr: float, only_ood: bool = True):\n",
    "    df = df.copy()\n",
    "    target_distributions = \"F(y|x)||G(y)\"\n",
    "    df = df.loc[df[\"distributions\"] == target_distributions]\n",
    "    k = get_k_given_frr(df, frr)\n",
    "    df['k'] = k\n",
    "    df['FRR'] = frr\n",
    "    df[\"log2_upper_bound_m\"] = df.apply(lambda x: get_log_upper_bound_m(x[\"ll2_generator\"], x[\"n_token_response\"], 1, k), axis=1)\n",
    "    df[\"log10_upper_bound_m\"] = df[\"log2_upper_bound_m\"] / np.log2(10)\n",
    "    df[\"log10_upper_bound_f\"] = df[\"ll2_model\"] / np.log2(10)\n",
    "    df[\"log10_constriction_ratio\"] = df[\"log10_upper_bound_f\"] - df[\"log10_upper_bound_m\"]\n",
    "\n",
    "    if only_ood:\n",
    "        return df.loc[df[\"OOD\"] == 1]\n",
    "    return df\n",
    "\n",
    "cr_figure_frr = 0.1\n",
    "df_constriction_ratios = get_constriction_ratios(df, cr_figure_frr, True)\n",
    "\n",
    "quantiles = [0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1.0]\n",
    "for q in quantiles:\n",
    "    print(f\"Quantile {q:.2f}: {df_constriction_ratios['log10_constriction_ratio'].quantile(q):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the plot\n",
    "# frr_list = [0.1] # Main paper\n",
    "frr_list = [0, 0.01, 0.05, 0.1, 0.25, 0.50] # Appendix\n",
    "show_x_axis_label = False # x axis label for last figure is always shown\n",
    "print_frr = True\n",
    "\n",
    "# get constriction ratios for each FRR and plot histograms\n",
    "for cr_figure_frr in frr_list:\n",
    "    df_constriction_ratios = get_constriction_ratios(df, cr_figure_frr, True)\n",
    "    print(f'k={df_constriction_ratios[\"k\"].unique().item()}')\n",
    "\n",
    "    plt.clf()\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.rcParams.update(styles.third)\n",
    "\n",
    "    g = sns.histplot(data=df_constriction_ratios, x=\"log10_constriction_ratio\", hue=\"Dataset\", stat=\"density\", common_norm=False, bins=40, palette=\"colorblind\", alpha=1.0)\n",
    "    # remove y axis label and ticks\n",
    "    g.set(ylabel=None)\n",
    "    g.set(yticklabels=[])\n",
    "\n",
    "    if not show_x_axis_label and cr_figure_frr != frr_list[-1]:\n",
    "        g.set(xlabel=None)\n",
    "    else:\n",
    "        g.set(xlabel=r\"$\\text{log}_{10}CR_{k}$ (Log Constriction Ratio)\")\n",
    "\n",
    "    if print_frr:\n",
    "        # print frr in top right corner\n",
    "        g.text(0.95, 0.95, f\"FRR = {cr_figure_frr:.2f}\", horizontalalignment='right', verticalalignment='top', transform=g.transAxes)\n",
    "\n",
    "    # remove legend\n",
    "    g.get_legend().remove()\n",
    "\n",
    "    # x axis limit to 0, max\n",
    "    min_value = -20\n",
    "    max_value = 105\n",
    "    g.set(xlim=(min_value, max_value))\n",
    "    fraction_below_min = (df_constriction_ratios[\"log10_constriction_ratio\"] < min_value).mean()\n",
    "    fraction_above_max = (df_constriction_ratios[\"log10_constriction_ratio\"] > max_value).mean()\n",
    "    if max_value is not None and fraction_above_max > 0.01:\n",
    "            rich.print(f\"[bold yellow]Warning:[/bold yellow] 1% of Log10 constriction ratios exceeds {max_value}.\")\n",
    "    if min_value is not None and fraction_below_min > 0.01:\n",
    "        rich.print(f\"[bold yellow]Warning:[/bold yellow] 1% of Log10 constriction ratios is below {min_value}.\")\n",
    "\n",
    "\n",
    "    # vertical bar at x=0\n",
    "    plt.axvline(x=0, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "    save_path = os.path.abspath(f\"cr_histograms/cr_hist_frr_{cr_figure_frr:.2f}_{DOMAIN}{EXPERIMENT_NAME}.pdf\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    print(f\"Saved figure to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomic Certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atomic_certificate_values(df, T, FRR):\n",
    "    df = df.copy()\n",
    "    results = []\n",
    "    k = get_k_given_frr(df, FRR)\n",
    "    print(f\"k={k}\")\n",
    "\n",
    "    df[\"log2_upper_bound_m\"] = df.apply(lambda x: get_log_upper_bound_m(x[\"ll2_generator\"], x[\"n_token_response\"], 1, k), axis=1)\n",
    "    df[\"log10_upper_bound_m\"] = df[\"log2_upper_bound_m\"] / np.log2(10)\n",
    "    df[\"log10_upper_bound_f\"] = df[\"ll2_model\"] / np.log2(10)\n",
    "    df[\"upper_bound_m\"] = 2 ** df[\"log2_upper_bound_m\"].astype(np.float128)\n",
    "    # set values above 10000 to nan. and values below 1e-300 to nan\n",
    "    df[\"upper_bound_m\"] = df[\"upper_bound_m\"].apply(lambda x: x if (x > 1e-300 and x < 10000) else 2e-300)\n",
    "    print(df[\"upper_bound_m\"].min())\n",
    "    print(df[\"upper_bound_m\"].max())\n",
    "    results = df[[\"log10_upper_bound_m\", \"upper_bound_m\", \"log10_upper_bound_f\", \"Dataset\", \"n_token_response\"]]\n",
    "    return results\n",
    "\n",
    "ac_ecdf_figure_frr = 0.1\n",
    "\n",
    "df_ac_values = get_atomic_certificate_values(df, 1, ac_ecdf_figure_frr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_legend = True\n",
    "y_axis_label_and_ticks = False\n",
    "\n",
    "plt.clf()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update(styles.third)\n",
    "\n",
    "hue_order = ['Target Domain $\\\\mathcal{D}_{T}$', 'Other $\\\\mathcal{D}_{F}$']\n",
    "\n",
    "palette = sns.color_palette()[:2][::-1]\n",
    "\n",
    "g = sns.ecdfplot(data=df_ac_values, x=\"log10_upper_bound_m\", hue=\"Dataset\", hue_order=hue_order, palette=palette)\n",
    "\n",
    "# set x limits\n",
    "g.set(xlim=(None, 10))\n",
    "g.set(xlabel=r\"$\\text{log}_{10}$ $\\epsilon_{\\mathbf{y}}$-AC\")\n",
    "g.set_title(\"Medical QA\", fontsize=8, pad=2)\n",
    "\n",
    "g.set(ylabel=None)\n",
    "if not y_axis_label_and_ticks:\n",
    "    g.set(yticklabels=[])\n",
    "\n",
    "if print_legend:\n",
    "    legend = g.get_legend()\n",
    "\n",
    "    # Move the legend to the exact corner\n",
    "    legend.set_bbox_to_anchor((-0.04, 1.06))  # Top-left corner of the axis\n",
    "    legend.set_loc(\"upper left\")  # Align to the upper left corner\n",
    "    # Remove legend title\n",
    "    legend.set_title(\"\")\n",
    "    # Customize legend line width and reduce padding\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(2)  # Adjust line width\n",
    "\n",
    "    # Adjust legend spacing\n",
    "    legend.set_frame_on(False)  # Remove the legend frame for a cleaner look\n",
    "else:\n",
    "    g.get_legend().remove()\n",
    "\n",
    "save_path = os.path.abspath(f\"epsilon_ac_ecdf_frr_{ac_ecdf_figure_frr:.2f}_{DOMAIN}{EXPERIMENT_NAME}.pdf\")\n",
    "plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "print(f\"Saved figure to {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
